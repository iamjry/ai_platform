# ç”Ÿç”¢ç’°å¢ƒå¿«é€Ÿå•Ÿå‹•æŒ‡å—
**ç›®æ¨™**: Red Hat Enterprise Linux v9 + 2x Nvidia H100 GPUs

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½² (5 æ­¥é©Ÿ)

### 1. å‰ç½®æª¢æŸ¥
```bash
# ç¢ºèªç³»çµ±
cat /etc/redhat-release  # æ‡‰é¡¯ç¤º RHEL 9.x

# ç¢ºèª GPU
nvidia-smi  # æ‡‰çœ‹åˆ° 2 å¼µ H100

# ç¢ºèª Docker
docker --version  # 24.0+
docker compose version  # 2.20+

# æ¸¬è©¦ GPU in Docker
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

### 2. é…ç½®ç’°å¢ƒè®Šæ•¸
```bash
cd /opt/ai-platform  # æˆ–æ‚¨çš„éƒ¨ç½²ç›®éŒ„

# è¤‡è£½ä¸¦ç·¨è¼¯ç’°å¢ƒè®Šæ•¸
cp .env.prod.template .env.prod
vim .env.prod

# å¿…é ˆä¿®æ”¹çš„å€¼:
# - POSTGRES_PASSWORD
# - REDIS_PASSWORD
# - RABBITMQ_DEFAULT_PASS
# - OPENAI_API_KEY
# - ANTHROPIC_API_KEY
# - LITELLM_MASTER_KEY
# - GRAFANA_ADMIN_PASSWORD
```

### 3. åŸ·è¡Œéƒ¨ç½²è…³æœ¬
```bash
# çµ¦äºˆåŸ·è¡Œæ¬Šé™
chmod +x deploy-prod.sh health-check.sh

# é–‹å§‹éƒ¨ç½²ï¼ˆå®Œæ•´æ¨¡å¼ï¼‰
./deploy-prod.sh

# é¸æ“‡é¸é … 1: å®Œæ•´éƒ¨ç½²
# é è¨ˆæ™‚é–“: 30-40 åˆ†é˜ï¼ˆé¦–æ¬¡ï¼‰
```

### 4. é©—è­‰éƒ¨ç½²
```bash
# åŸ·è¡Œå¥åº·æª¢æŸ¥
./health-check.sh

# é æœŸçµæœ: æ‰€æœ‰æœå‹™ âœ… Healthy
```

### 5. è¨ªå•æœå‹™
```bash
# ç²å–ä¼ºæœå™¨ IP
hostname -I

# è¨ªå• Web UI
http://<SERVER_IP>:8501
```

---

## ğŸ“Š GPU é…ç½®

### GPU åˆ†é…
- **GPU 0**: Ollama (æœ¬åœ° LLM)
- **GPU 1**: MCP Server (DeepSeek-OCR)

### é©—è­‰ GPU ä½¿ç”¨
```bash
# æŒçºŒç›£æ§
watch -n 1 nvidia-smi

# æª¢æŸ¥å®¹å™¨ GPU
docker inspect ai-ollama-prod | jq '.[0].HostConfig.DeviceRequests'
docker inspect ai-mcp-server-prod | jq '.[0].HostConfig.DeviceRequests'
```

### æ¸¬è©¦ OCR GPU å¾Œç«¯
```bash
curl http://localhost:8001/tools/ocr_get_status | jq .

# é æœŸçœ‹åˆ°:
# "DeepSeek-OCR": {
#   "available": true,
#   "cuda_available": true
# }
```

---

## ğŸ”§ å¸¸ç”¨æŒ‡ä»¤

### æœå‹™ç®¡ç†
```bash
# å•Ÿå‹•
docker compose --env-file .env.prod -f docker-compose.prod.yml up -d

# åœæ­¢
docker compose --env-file .env.prod -f docker-compose.prod.yml down

# é‡å•Ÿç‰¹å®šæœå‹™
docker compose --env-file .env.prod -f docker-compose.prod.yml restart mcp-server

# æŸ¥çœ‹æ—¥èªŒ
docker compose --env-file .env.prod -f docker-compose.prod.yml logs -f mcp-server
```

### ç›£æ§
```bash
# å¥åº·æª¢æŸ¥
./health-check.sh

# GPU ç›£æ§
nvidia-smi -l 1

# å®¹å™¨è³‡æº
docker stats

# ç³»çµ±è³‡æº
htop
```

### ç¶­è­·
```bash
# å‚™ä»½è³‡æ–™åº«
docker exec ai-postgres-prod pg_dump -U ai_platform_user ai_platform_prod > backup.sql

# æ¸…ç†æœªä½¿ç”¨æ˜ åƒæª”
docker system prune -a

# æŸ¥çœ‹ç£ç¢Ÿä½¿ç”¨
df -h
docker system df
```

---

## ğŸ¯ æœå‹™ç«¯å£

| æœå‹™ | ç«¯å£ | èªªæ˜ |
|------|------|------|
| Web UI | 8501 | ä¸»è¦ä½¿ç”¨è€…ç•Œé¢ |
| Agent Service | 8002 | Agent åŸ·è¡Œå¼•æ“ |
| MCP Server | 8001 | å·¥å…·èˆ‡ OCR æœå‹™ |
| LiteLLM | 4000 | LLM ä»£ç† |
| Grafana | 3000 | ç›£æ§å„€è¡¨æ¿ |
| Prometheus | 9090 | æŒ‡æ¨™æ”¶é›† |
| PostgreSQL | 5433 | è³‡æ–™åº« |
| Redis | 6380 | å¿«å– |
| RabbitMQ | 5672, 15672 | è¨Šæ¯ä½‡åˆ— |

---

## âš¡ æ•ˆèƒ½æŒ‡æ¨™

### GPU OCR æ•ˆèƒ½
- **DeepSeek-OCR**: 0.5-1 ç§’/é 
- **EasyOCR (CPU fallback)**: 2-5 ç§’/é 
- **è¨˜æ†¶é«”**: ~10-15 GB VRAM

### ç³»çµ±è³‡æº
- **ç¸½è¨˜æ†¶é«”**: å»ºè­° 128GB+
- **CPU**: å»ºè­° 16+ cores
- **å„²å­˜**: 2TB+ NVMe SSD

### ä¸¦ç™¼èƒ½åŠ›
- **Web UI**: 50+ ä¸¦ç™¼ç”¨æˆ¶
- **API**: 100+ requests/sec
- **OCR**: 10+ ä¸¦ç™¼è™•ç†

---

## â— ç–‘é›£æ’è§£

### å•é¡Œ: GPU ç„¡æ³•ä½¿ç”¨

```bash
# é‡æ–°é…ç½® NVIDIA runtime
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# é©—è­‰
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

### å•é¡Œ: DeepSeek-OCR æœªå•Ÿç”¨

```bash
# æª¢æŸ¥æ—¥èªŒ
docker logs ai-mcp-server-prod | grep -i cuda

# é€²å…¥å®¹å™¨æ¸¬è©¦
docker exec -it ai-mcp-server-prod python3 -c "import torch; print(torch.cuda.is_available())"

# é‡å•Ÿæœå‹™
docker compose --env-file .env.prod -f docker-compose.prod.yml restart mcp-server
```

### å•é¡Œ: æœå‹™ç„¡æ³•å•Ÿå‹•

```bash
# æª¢æŸ¥æ—¥èªŒ
docker compose --env-file .env.prod -f docker-compose.prod.yml logs <service>

# æª¢æŸ¥è³‡æº
free -h
df -h

# æª¢æŸ¥ç«¯å£å ç”¨
ss -tulpn | grep -E "8501|8002|8001|4000"
```

### å•é¡Œ: SELinux é˜»æ­¢

```bash
# æŸ¥çœ‹ SELinux ç‹€æ…‹
getenforce

# è‡¨æ™‚é—œé–‰ï¼ˆæ¸¬è©¦ç”¨ï¼‰
sudo setenforce 0

# æ°¸ä¹…é…ç½®ï¼ˆå»ºè­°ï¼‰
sudo chcon -R -t container_file_t /opt/ai-platform
```

---

## ğŸ”’ å®‰å…¨æª¢æŸ¥æ¸…å–®

- [ ] ä¿®æ”¹æ‰€æœ‰é è¨­å¯†ç¢¼
- [ ] .env.prod æ¬Šé™è¨­ç‚º 600
- [ ] é…ç½®é˜²ç«ç‰†è¦å‰‡
- [ ] å•Ÿç”¨ SSL/TLS (Nginx + Let's Encrypt)
- [ ] é™åˆ¶å¤–éƒ¨è¨ªå•ç«¯å£
- [ ] å•Ÿç”¨æ—¥èªŒå¯©è¨ˆ
- [ ] å®šæœŸå®‰å…¨æ›´æ–°
- [ ] å‚™ä»½ç­–ç•¥å·²è¨­å®š

---

## ğŸ“š å®Œæ•´æ–‡æª”

è©³ç´°è³‡è¨Šè«‹åƒè€ƒ:

- **å®Œæ•´éƒ¨ç½²æŒ‡å—**: `RHEL9_DEPLOYMENT_GUIDE.md`
- **å¹³å°ç‹€æ³**: `PLATFORM_STATUS.md`
- **OCR æ¸¬è©¦**: `OCR_TESTING_GUIDE.md`
- **å°ˆæ¡ˆç¸½è¦½**: `PROJECT_OVERVIEW.md`

---

## ğŸ†˜ ç²å–å¹«åŠ©

### æŸ¥çœ‹æ—¥èªŒ
```bash
# æ‰€æœ‰æœå‹™
docker compose --env-file .env.prod -f docker-compose.prod.yml logs -f

# ç‰¹å®šæœå‹™
docker compose --env-file .env.prod -f docker-compose.prod.yml logs -f mcp-server

# æœ€è¿‘ 100 è¡Œ
docker logs --tail 100 ai-mcp-server-prod
```

### æª¢æŸ¥é…ç½®
```bash
# Docker Compose é…ç½®
docker compose --env-file .env.prod -f docker-compose.prod.yml config

# ç’°å¢ƒè®Šæ•¸
docker exec ai-mcp-server-prod env | grep -i cuda
```

---

**éƒ¨ç½²æ”¯æ´**: åƒè€ƒ `RHEL9_DEPLOYMENT_GUIDE.md` ç²å–è©³ç´°èªªæ˜

**éƒ¨ç½²æ™‚é–“**: é¦–æ¬¡ ~40 åˆ†é˜ | å¾ŒçºŒ ~10 åˆ†é˜

**ç³»çµ±å°±ç·’**: åŸ·è¡Œ `./health-check.sh` ç¢ºèªæ‰€æœ‰æœå‹™å¥åº· âœ…
