# AI Platform é›¢ç·šéƒ¨ç½²æŒ‡å—

**é©ç”¨å ´æ™¯ï¼šç„¡æ³•é€éç¶²è·¯ç›´æ¥é€£ç·šåˆ°ç”Ÿç”¢ä¼ºæœå™¨**

---

## ğŸ“‹ ç›®éŒ„

1. [é©ç”¨å ´æ™¯](#é©ç”¨å ´æ™¯)
2. [æº–å‚™éƒ¨ç½²åŒ…](#æº–å‚™éƒ¨ç½²åŒ…)
3. [è¤‡è£½åˆ°ä¼ºæœå™¨](#è¤‡è£½åˆ°ä¼ºæœå™¨)
4. [ä¼ºæœå™¨ä¸ŠåŸ·è¡Œéƒ¨ç½²](#ä¼ºæœå™¨ä¸ŠåŸ·è¡Œéƒ¨ç½²)
5. [æ‰‹å‹•é©—è­‰](#æ‰‹å‹•é©—è­‰)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## é©ç”¨å ´æ™¯

ä»¥ä¸‹æƒ…æ³éœ€è¦ä½¿ç”¨é›¢ç·šéƒ¨ç½²ï¼š

- âœ… ä¼ºæœå™¨åœ¨å…§ç¶²ï¼Œç„¡æ³•ç›´æ¥ SSH é€£ç·š
- âœ… éœ€è¦é€éè·³æ¿æ©Ÿæˆ– VPN æ‰èƒ½è¨ªå•
- âœ… å®‰å…¨æ”¿ç­–é™åˆ¶ç¶²è·¯é€£ç·š
- âœ… ä½¿ç”¨ USB éš¨èº«ç¢Ÿ/å¤–æ¥ç¡¬ç¢Ÿé€²è¡Œå¯¦é«”å‚³è¼¸
- âœ… éœ€è¦åœ¨éš”é›¢ç’°å¢ƒä¸­éƒ¨ç½²

---

## æº–å‚™éƒ¨ç½²åŒ…

### æ­¥é©Ÿ 1: åœ¨æœ¬åœ°é–‹ç™¼æ©ŸåŸ·è¡Œæ‰“åŒ…

```bash
# åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„
cd /path/to/your/ai_platform

# åŸ·è¡Œæ‰“åŒ…è…³æœ¬
./scripts/1-package-deployment.sh
```

**è¼¸å‡º:**
```
ai_platform_20251029_220000.tar.gz  (å®Œæ•´éƒ¨ç½²åŒ…)
```

### æ­¥é©Ÿ 2: ç¢ºèªæ‰“åŒ…å…§å®¹

```bash
# æŸ¥çœ‹å£“ç¸®åŒ…å¤§å°
ls -lh ai_platform_*.tar.gz

# æŸ¥çœ‹å£“ç¸®åŒ…å…§å®¹
tar -tzf ai_platform_*.tar.gz | head -20

# è¨ˆç®— MD5 æ ¡é©—ç¢¼ï¼ˆç”¨æ–¼é©—è­‰å®Œæ•´æ€§ï¼‰
md5sum ai_platform_*.tar.gz > ai_platform.md5
```

### æ­¥é©Ÿ 3: éœ€è¦è¤‡è£½çš„æª”æ¡ˆæ¸…å–®

**å¿…é ˆè¤‡è£½çš„æª”æ¡ˆï¼š**

```
ai_platform_YYYYMMDD_HHMMSS.tar.gz  (ä¸»è¦éƒ¨ç½²åŒ…)
ai_platform.md5                      (MD5 æ ¡é©—ç¢¼)
```

**å¯é¸æª”æ¡ˆï¼ˆæ–¹ä¾¿åƒè€ƒï¼‰ï¼š**

```
STEP_BY_STEP_DEPLOYMENT.md           (éƒ¨ç½²æŒ‡å—)
DEPLOYMENT_QUICK_REFERENCE.md        (å¿«é€Ÿåƒè€ƒ)
OFFLINE_DEPLOYMENT_GUIDE.md          (æœ¬æŒ‡å—)
```

---

## è¤‡è£½åˆ°ä¼ºæœå™¨

### æ–¹æ³• A: ä½¿ç”¨ USB éš¨èº«ç¢Ÿ/å¤–æ¥ç¡¬ç¢Ÿ

#### åœ¨æœ¬åœ°é–‹ç™¼æ©Ÿï¼š

```bash
# å‡è¨­ USB éš¨èº«ç¢Ÿæ›è¼‰åœ¨ /Volumes/USB
USB_PATH="/Volumes/USB"

# è¤‡è£½éƒ¨ç½²åŒ…
cp ai_platform_*.tar.gz "${USB_PATH}/"
cp ai_platform.md5 "${USB_PATH}/"

# è¤‡è£½æ–‡æª”ï¼ˆå¯é¸ï¼‰
cp STEP_BY_STEP_DEPLOYMENT.md "${USB_PATH}/"
cp DEPLOYMENT_QUICK_REFERENCE.md "${USB_PATH}/"
cp OFFLINE_DEPLOYMENT_GUIDE.md "${USB_PATH}/"

# å®‰å…¨é€€å‡º USB
diskutil eject /Volumes/USB
```

#### åœ¨ç”Ÿç”¢ä¼ºæœå™¨ï¼š

```bash
# æ›è¼‰ USB éš¨èº«ç¢Ÿ
# RHEL é€šå¸¸è‡ªå‹•æ›è¼‰åœ¨ /run/media/<username>/USB_NAME
# æˆ–æ‰‹å‹•æ›è¼‰
mkdir -p /mnt/usb
mount /dev/sdb1 /mnt/usb

# è¤‡è£½åˆ°ä¼ºæœå™¨
mkdir -p /opt/ai_platform
cp /mnt/usb/ai_platform_*.tar.gz /opt/ai_platform/
cp /mnt/usb/ai_platform.md5 /opt/ai_platform/

# é€€å‡º USB
umount /mnt/usb
```

### æ–¹æ³• B: é€éè·³æ¿æ©Ÿ (Jump Host)

```bash
# æ­¥é©Ÿ 1: å¾æœ¬åœ°è¤‡è£½åˆ°è·³æ¿æ©Ÿ
scp ai_platform_*.tar.gz user@jumphost:/tmp/
scp ai_platform.md5 user@jumphost:/tmp/

# æ­¥é©Ÿ 2: ç™»å…¥è·³æ¿æ©Ÿ
ssh user@jumphost

# æ­¥é©Ÿ 3: å¾è·³æ¿æ©Ÿè¤‡è£½åˆ°ç›®æ¨™ä¼ºæœå™¨
scp /tmp/ai_platform_*.tar.gz root@target-server:/opt/ai_platform/
scp /tmp/ai_platform.md5 root@target-server:/opt/ai_platform/
```

### æ–¹æ³• C: é€éå…±äº«ç£ç¢Ÿ/NFS

```bash
# åœ¨æœ¬åœ°è¤‡è£½åˆ°å…±äº«ç£ç¢Ÿ
cp ai_platform_*.tar.gz /mnt/shared_storage/
cp ai_platform.md5 /mnt/shared_storage/

# åœ¨ç”Ÿç”¢ä¼ºæœå™¨è®€å–
cp /mnt/shared_storage/ai_platform_*.tar.gz /opt/ai_platform/
cp /mnt/shared_storage/ai_platform.md5 /opt/ai_platform/
```

### æ–¹æ³• D: åˆ†ç‰‡å‚³è¼¸ï¼ˆæª”æ¡ˆéå¤§æ™‚ï¼‰

```bash
# åœ¨æœ¬åœ°åˆ†ç‰‡ï¼ˆæ¯ç‰‡ 500MBï¼‰
split -b 500M ai_platform_*.tar.gz ai_platform_part_

# ç”¢ç”Ÿåˆ†ç‰‡åˆ—è¡¨
ls ai_platform_part_* > parts.list

# å‚³è¼¸æ‰€æœ‰åˆ†ç‰‡åˆ°ä¼ºæœå™¨
# ï¼ˆé€éä»»ä½•å¯ç”¨æ–¹å¼ï¼‰

# åœ¨ä¼ºæœå™¨ä¸Šåˆä½µ
cat ai_platform_part_* > ai_platform_YYYYMMDD_HHMMSS.tar.gz

# æ¸…ç†åˆ†ç‰‡
rm ai_platform_part_*
```

---

## ä¼ºæœå™¨ä¸ŠåŸ·è¡Œéƒ¨ç½²

### æ­¥é©Ÿ 1: é©—è­‰æª”æ¡ˆå®Œæ•´æ€§

```bash
# é€£ç·šåˆ°ç”Ÿç”¢ä¼ºæœå™¨ï¼ˆé€éçµ‚ç«¯æ©Ÿæˆ– KVMï¼‰
cd /opt/ai_platform

# é©—è­‰ MD5
md5sum -c ai_platform.md5

# æ‡‰è©²çœ‹åˆ°:
# ai_platform_20251029_220000.tar.gz: OK
```

### æ­¥é©Ÿ 2: è§£å£“éƒ¨ç½²åŒ…

```bash
cd /opt/ai_platform

# è§£å£“
tar -xzf ai_platform_*.tar.gz

# é©—è­‰è§£å£“å…§å®¹
ls -la

# æ‡‰è©²çœ‹åˆ°:
# docker-compose.production.yml
# .env.production.example
# deploy-rhel-production.sh
# services/
# config/
# systemd/
# load-tests/
# scripts/
```

### æ­¥é©Ÿ 3: è¨­ç½®åŸ·è¡Œæ¬Šé™

```bash
cd /opt/ai_platform

# è¨­ç½®è…³æœ¬åŸ·è¡Œæ¬Šé™
chmod +x deploy-rhel-production.sh
chmod +x systemd/*.sh
chmod +x load-tests/*.sh
chmod +x scripts/*.sh
```

### æ­¥é©Ÿ 4: é…ç½®ç’°å¢ƒè®Šæ•¸

```bash
# è¤‡è£½ç’°å¢ƒè®Šæ•¸ç¯„æœ¬
cp .env.production.example .env

# ç·¨è¼¯ç’°å¢ƒè®Šæ•¸
vim .env

# æˆ–ä½¿ç”¨ nano
nano .env
```

**å¿…é ˆä¿®æ”¹çš„é …ç›®ï¼š**

```bash
# API é‡‘é‘°
OPENAI_API_KEY=sk-your-actual-openai-key
ANTHROPIC_API_KEY=sk-ant-your-actual-anthropic-key
GOOGLE_API_KEY=your-actual-gemini-key

# è³‡æ–™åº«å¯†ç¢¼ï¼ˆä½¿ç”¨å¼·å¯†ç¢¼ï¼‰
POSTGRES_PASSWORD=YourStrongPassword123!
REDIS_PASSWORD=YourRedisPassword456!
RABBITMQ_DEFAULT_PASS=YourRabbitMQPassword789!

# GPU è¨­å®šï¼ˆç¢ºèªï¼‰
ENABLE_GPU=true
CUDA_VISIBLE_DEVICES=0,1

# åŸŸåè¨­å®š
DOMAIN=your-domain.com  # æˆ– localhost
```

**ä¿è­·ç’°å¢ƒè®Šæ•¸æª”æ¡ˆï¼š**

```bash
chmod 600 .env
chown root:root .env
```

### æ­¥é©Ÿ 5: æª¢æŸ¥ç³»çµ±ä¾è³´

```bash
# æª¢æŸ¥ä½œæ¥­ç³»çµ±
cat /etc/redhat-release

# æª¢æŸ¥ NVIDIA é©…å‹•
nvidia-smi

# æª¢æŸ¥ Docker
docker --version
docker compose version

# æª¢æŸ¥ NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi
```

**å¦‚æœä¾è³´ç¼ºå¤±ï¼Œè«‹åƒè€ƒ `STEP_BY_STEP_DEPLOYMENT.md` æ­¥é©Ÿ 4-6 é€²è¡Œå®‰è£ã€‚**

### æ­¥é©Ÿ 6: åŸ·è¡Œéƒ¨ç½²è…³æœ¬

```bash
cd /opt/ai_platform

# åŸ·è¡Œéƒ¨ç½²
sudo ./deploy-rhel-production.sh

# éƒ¨ç½²æœƒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
# 1. æª¢æŸ¥ç³»çµ±ä¾è³´
# 2. é…ç½®é˜²ç«ç‰†
# 3. æ‹‰å– Docker æ˜ åƒ
# 4. å•Ÿå‹•åŸºç¤è¨­æ–½æœå‹™
# 5. å•Ÿå‹• LLM æœå‹™
# 6. å•Ÿå‹•æ‡‰ç”¨æœå‹™
# 7. å•Ÿå‹•ç›£æ§æœå‹™
# 8. é©—è­‰éƒ¨ç½²ç‹€æ…‹
```

**é è¨ˆæ™‚é–“:** 20-30 åˆ†é˜

### æ­¥é©Ÿ 7: ç›£æ§éƒ¨ç½²é€²åº¦

åœ¨å¦ä¸€å€‹çµ‚ç«¯è¦–çª—ä¸­ï¼š

```bash
# æŸ¥çœ‹å®¹å™¨ç‹€æ…‹
watch -n 2 'docker ps --format "table {{.Names}}\t{{.Status}}"'

# æŸ¥çœ‹æ—¥èªŒ
docker compose -f /opt/ai_platform/docker-compose.production.yml logs -f

# æŸ¥çœ‹ GPU ä½¿ç”¨
watch -n 1 nvidia-smi
```

---

## æ‰‹å‹•é©—è­‰

### é©—è­‰ 1: æª¢æŸ¥å®¹å™¨ç‹€æ…‹

```bash
cd /opt/ai_platform

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨
docker ps

# æ‡‰è©²çœ‹åˆ°ä»¥ä¸‹å®¹å™¨é‹è¡Œä¸­ï¼š
# - ai-postgres-prod
# - ai-redis-prod
# - ai-qdrant-prod
# - ai-rabbitmq-prod
# - ai-ollama-prod
# - ai-litellm-prod
# - ai-mcp-server-1, ai-mcp-server-2, ai-mcp-server-3
# - ai-agent-service-1, ai-agent-service-2, ai-agent-service-3
# - ai-web-ui-1, ai-web-ui-2
# - ai-prometheus-prod
# - ai-grafana-prod
# - ai-nginx-prod

# æª¢æŸ¥åœæ­¢çš„å®¹å™¨
docker ps -a --filter "status=exited"

# å¦‚æœæœ‰å®¹å™¨åœæ­¢ï¼ŒæŸ¥çœ‹æ—¥èªŒ
docker logs <container-name>
```

### é©—è­‰ 2: æ¸¬è©¦ API ç«¯é»

```bash
# æ¸¬è©¦ MCP Server
curl -s http://localhost:8001/health | jq .

# æ¸¬è©¦ Agent Service
curl -s http://localhost:8000/health | jq .

# æ¸¬è©¦ LiteLLM
curl -s http://localhost:4000/health | jq .

# æ¸¬è©¦ Web UI
curl -s http://localhost:8501

# æ¸¬è©¦ Grafana
curl -s http://localhost:3000/api/health | jq .
```

### é©—è­‰ 3: æª¢æŸ¥ GPU ç‹€æ…‹

```bash
# ä¸»æ©Ÿ GPU
nvidia-smi

# æª¢æŸ¥æº«åº¦å’Œä½¿ç”¨ç‡
nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv

# å®¹å™¨å…§ GPU
docker exec ai-ollama-prod nvidia-smi
```

### é©—è­‰ 4: æ¸¬è©¦è³‡æ–™åº«é€£ç·š

```bash
# PostgreSQL
docker exec ai-postgres-prod pg_isready

# Redis
docker exec ai-redis-prod redis-cli ping

# æ‡‰è©²å›æ‡‰: PONG
```

### é©—è­‰ 5: æª¢æŸ¥æ—¥èªŒ

```bash
# æŸ¥çœ‹æœ€è¿‘éŒ¯èª¤
docker compose logs --tail=100 | grep -i error

# æŸ¥çœ‹ç‰¹å®šæœå‹™
docker compose logs agent-service --tail=50

# æŒçºŒç›£æ§
docker compose logs -f
```

### é©—è­‰ 6: æª¢æŸ¥ç³»çµ±è³‡æº

```bash
# CPU å’Œè¨˜æ†¶é«”
top
# æˆ–
htop

# ç£ç¢Ÿç©ºé–“
df -h

# å®¹å™¨è³‡æºä½¿ç”¨
docker stats --no-stream

# ç¶²è·¯ç«¯å£
ss -tlnp | grep -E ':(8000|8001|8501|3000|11434)'
```

---

## æ‰‹å‹•è² è¼‰æ¸¬è©¦

### å¿«é€Ÿç…™éœ§æ¸¬è©¦

```bash
cd /opt/ai_platform/load-tests

# åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦ï¼ˆ5 ç”¨æˆ¶, 100 è«‹æ±‚ï¼‰
BASE_URL=http://localhost:8001 \
CONCURRENT_USERS=5 \
TOTAL_REQUESTS=100 \
./test-api-endpoints.sh

# æŸ¥çœ‹çµæœ
cat results_*/SUMMARY.txt
```

### å®Œæ•´è² è¼‰æ¸¬è©¦

```bash
cd /opt/ai_platform/load-tests

# å®‰è£æ¸¬è©¦å·¥å…·
pip3 install -r requirements.txt

# åŸ·è¡Œè² è¼‰æ¸¬è©¦ï¼ˆ50 ç”¨æˆ¶, 10 åˆ†é˜ï¼‰
locust -f locustfile.py \
    --host=http://localhost:8001 \
    --users 50 \
    --spawn-rate 5 \
    --run-time 10m \
    --headless \
    --csv=results/load_test
```

---

## é…ç½® Systemd è‡ªå‹•å•Ÿå‹•

```bash
cd /opt/ai_platform/systemd

# åŸ·è¡Œå®‰è£è…³æœ¬
sudo ./install-systemd.sh

# é©—è­‰æœå‹™
sudo systemctl status ai-platform
sudo systemctl status ai-platform-backup.timer
sudo systemctl status ai-platform-healthcheck.timer

# æ¸¬è©¦é‡å•Ÿ
sudo systemctl restart ai-platform

# æŸ¥çœ‹æ—¥èªŒ
sudo journalctl -u ai-platform -f
```

---

## è¨ªå•æœå‹™

### æœå‹™ URL

| æœå‹™ | URL | é è¨­å¸³å¯† |
|------|-----|---------|
| **Web UI** | http://server-ip:8501 | - |
| **API (MCP)** | http://server-ip:8001 | - |
| **Agent Service** | http://server-ip:8000 | - |
| **Grafana** | http://server-ip:3000 | admin / (è¦‹ .env) |
| **Prometheus** | http://server-ip:9090 | - |
| **Ollama** | http://server-ip:11434 | - |

### å¾æœ¬åœ°ç€è¦½å™¨è¨ªå•

å¦‚æœä¼ºæœå™¨åœ¨å…§ç¶²ï¼Œå¯ä»¥ä½¿ç”¨ SSH éš§é“ï¼š

```bash
# åœ¨æœ¬åœ°æ©Ÿå™¨åŸ·è¡Œ
ssh -L 8501:localhost:8501 \
    -L 8001:localhost:8001 \
    -L 3000:localhost:3000 \
    root@server-ip

# ç„¶å¾Œåœ¨ç€è¦½å™¨è¨ªå•
# http://localhost:8501  (Web UI)
# http://localhost:3000  (Grafana)
```

---

## æ•…éšœæ’é™¤

### å•é¡Œ 1: è§£å£“å¤±æ•—

**ç—‡ç‹€:**
```
tar: Error opening archive: Failed to open
```

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æª¢æŸ¥æª”æ¡ˆå®Œæ•´æ€§
md5sum ai_platform_*.tar.gz

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h /opt

# é‡æ–°å‚³è¼¸æª”æ¡ˆ
```

### å•é¡Œ 2: Docker æ˜ åƒæ‹‰å–å¤±æ•—

**ç—‡ç‹€:**
```
Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: TLS handshake timeout
```

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æª¢æŸ¥ç¶²è·¯é€£ç·š
ping 8.8.8.8

# é…ç½® Docker ä»£ç†ï¼ˆå¦‚éœ€è¦ï¼‰
sudo mkdir -p /etc/systemd/system/docker.service.d
sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf

# æ·»åŠ ï¼š
# [Service]
# Environment="HTTP_PROXY=http://proxy:port"
# Environment="HTTPS_PROXY=http://proxy:port"

sudo systemctl daemon-reload
sudo systemctl restart docker
```

### å•é¡Œ 3: GPU ç„¡æ³•è¨ªå•

**ç—‡ç‹€:**
```
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æª¢æŸ¥ NVIDIA é©…å‹•
nvidia-smi

# é‡æ–°é…ç½® NVIDIA Container Toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# æ¸¬è©¦ GPU è¨ªå•
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi
```

### å•é¡Œ 4: ç’°å¢ƒè®Šæ•¸æœªç”Ÿæ•ˆ

**ç—‡ç‹€:**
```
å®¹å™¨å•Ÿå‹•å¤±æ•—ï¼Œæ—¥èªŒé¡¯ç¤ºç¼ºå°‘ API é‡‘é‘°
```

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æª¢æŸ¥ .env æ–‡ä»¶
cat .env | grep API_KEY

# ç¢ºèªæ¬Šé™
ls -l .env

# é‡æ–°å•Ÿå‹•å®¹å™¨
docker compose down
docker compose up -d
```

### å•é¡Œ 5: ç«¯å£è¢«ä½”ç”¨

**ç—‡ç‹€:**
```
Error starting userland proxy: listen tcp4 0.0.0.0:8001: bind: address already in use
```

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æŸ¥æ‰¾ä½”ç”¨ç«¯å£çš„é€²ç¨‹
sudo lsof -i :8001
# æˆ–
sudo ss -tlnp | grep :8001

# åœæ­¢ä½”ç”¨é€²ç¨‹
sudo kill -9 <PID>

# é‡æ–°å•Ÿå‹•æœå‹™
docker compose up -d
```

---

## é›¢ç·šéƒ¨ç½²æª¢æŸ¥æ¸…å–®

### æº–å‚™éšæ®µ
- [ ] å·²åŸ·è¡Œæ‰“åŒ…è…³æœ¬
- [ ] å·²ç”Ÿæˆ MD5 æ ¡é©—ç¢¼
- [ ] å·²æº–å‚™å‚³è¼¸åª’ä»‹ï¼ˆUSB/è·³æ¿æ©Ÿ/å…±äº«ç£ç¢Ÿï¼‰
- [ ] å·²è¤‡è£½æ–‡æª”ï¼ˆå¯é¸ï¼‰

### å‚³è¼¸éšæ®µ
- [ ] å·²è¤‡è£½éƒ¨ç½²åŒ…åˆ°ä¼ºæœå™¨
- [ ] å·²è¤‡è£½ MD5 æ ¡é©—ç¢¼
- [ ] å·²é©—è­‰æª”æ¡ˆå®Œæ•´æ€§

### éƒ¨ç½²éšæ®µ
- [ ] å·²è§£å£“éƒ¨ç½²åŒ…
- [ ] å·²è¨­ç½®åŸ·è¡Œæ¬Šé™
- [ ] å·²é…ç½®ç’°å¢ƒè®Šæ•¸
- [ ] å·²æª¢æŸ¥ç³»çµ±ä¾è³´
- [ ] å·²åŸ·è¡Œéƒ¨ç½²è…³æœ¬

### é©—è­‰éšæ®µ
- [ ] æ‰€æœ‰å®¹å™¨é‹è¡Œä¸­
- [ ] API ç«¯é»å›æ‡‰æ­£å¸¸
- [ ] GPU æ­£å¸¸é‹ä½œ
- [ ] è³‡æ–™åº«é€£ç·šæ­£å¸¸
- [ ] ç„¡éŒ¯èª¤æ—¥èªŒ

### å®Œæˆéšæ®µ
- [ ] å·²é…ç½® Systemd è‡ªå‹•å•Ÿå‹•
- [ ] å·²åŸ·è¡Œç…™éœ§æ¸¬è©¦
- [ ] å·²è¨ªå• Grafana å„€è¡¨æ¿
- [ ] å·²è¨­ç½®ç›£æ§å‘Šè­¦

---

## å¿«é€Ÿå‘½ä»¤åƒè€ƒ

```bash
# === ä¼ºæœå™¨ä¸Šçš„å¸¸ç”¨å‘½ä»¤ ===

# åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„
cd /opt/ai_platform

# æŸ¥çœ‹å®¹å™¨ç‹€æ…‹
docker ps

# æŸ¥çœ‹æ—¥èªŒ
docker compose logs -f

# é‡å•Ÿæœå‹™
docker compose restart

# åœæ­¢æœå‹™
docker compose down

# å•Ÿå‹•æœå‹™
docker compose up -d

# æŸ¥çœ‹ GPU
nvidia-smi

# æ¸¬è©¦ API
curl http://localhost:8001/health

# æŸ¥çœ‹ç³»çµ±è³‡æº
htop
df -h
docker stats
```

---

## ç¸½çµ

é›¢ç·šéƒ¨ç½²æµç¨‹ï¼š

1. **æœ¬åœ°** â†’ æ‰“åŒ…éƒ¨ç½²æ–‡ä»¶
2. **å‚³è¼¸** â†’ è¤‡è£½åˆ°ä¼ºæœå™¨ï¼ˆUSB/è·³æ¿æ©Ÿ/å…±äº«ç£ç¢Ÿï¼‰
3. **ä¼ºæœå™¨** â†’ è§£å£“ä¸¦åŸ·è¡Œéƒ¨ç½²
4. **é©—è­‰** â†’ ç¢ºèªæœå‹™æ­£å¸¸é‹è¡Œ
5. **å®Œæˆ** â†’ é…ç½®è‡ªå‹•å•Ÿå‹•å’Œç›£æ§

**é è¨ˆæ™‚é–“:** 30-45 åˆ†é˜ï¼ˆä¸å«å‚³è¼¸æ™‚é–“ï¼‰

---

**ç‰ˆæœ¬:** 2.0.0
**æœ€å¾Œæ›´æ–°:** 2025-10-29
**æ–‡æª”ç¶­è­·:** AI Platform DevOps Team
