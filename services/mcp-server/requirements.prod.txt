# Production Requirements for MCP Server with GPU Support
# Target: RHEL 9 with Nvidia H100 GPUs and CUDA 12.2

# Core FastAPI and async
fastapi==0.110.0
uvicorn[standard]==0.29.0
pydantic==2.7.0
pydantic-settings==2.2.1

# Database and Storage
asyncpg==0.29.0
qdrant-client==1.9.0
redis==5.0.3

# HTTP and networking
aiohttp==3.9.5
httpx==0.27.0
python-multipart==0.0.9

# Monitoring
prometheus-fastapi-instrumentator==6.1.0

# Data processing
pandas==2.2.0
openpyxl==3.1.2

# Document processing
PyPDF2==3.0.1
python-docx==1.1.0
pdfplumber==0.10.4
pdf2image==1.16.3
Pillow==10.2.0

# Search APIs
duckduckgo-search==5.3.0
google-api-python-client==2.117.0
tavily-python==0.3.3
serpapi==0.1.5

# RAG and embeddings
sentence-transformers==2.6.1

# CPU-based OCR (fallback)
easyocr==1.7.0

# GPU-based OCR and AI (Production with CUDA support)
# Note: torch installed separately via PyTorch.org index for CUDA 12.1
transformers==4.38.1
accelerate==0.27.2
sentencepiece==0.2.0
protobuf==4.25.3

# Flash Attention for efficient transformer inference (H100 optimized)
# Requires CUDA 12.x and will be compiled during build
flash-attn==2.5.5

# Additional GPU utilities
nvidia-ml-py==12.535.133

# Production utilities
python-json-logger==2.0.7
psutil==5.9.8
