#!/bin/bash
# Production Deployment Script for AI Platform
# Target: RHEL 9 with 2x Nvidia H100 GPUs

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Print functions
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  $1"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
}

# Check if running as root
if [ "$EUID" -eq 0 ]; then
    print_error "è«‹ä¸è¦ä»¥ root èº«åˆ†åŸ·è¡Œæ­¤è…³æœ¬"
    exit 1
fi

print_header "AI Platform ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²è…³æœ¬"

# Check prerequisites
print_info "æª¢æŸ¥ç³»çµ±éœ€æ±‚..."

# Check RHEL version
if [ -f /etc/redhat-release ]; then
    RHEL_VERSION=$(cat /etc/redhat-release)
    print_success "ä½œæ¥­ç³»çµ±: $RHEL_VERSION"
else
    print_error "ç„¡æ³•æª¢æ¸¬ RHEL ç‰ˆæœ¬"
    exit 1
fi

# Check Docker
if command -v docker &> /dev/null; then
    DOCKER_VERSION=$(docker --version)
    print_success "$DOCKER_VERSION"
else
    print_error "Docker æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ Docker"
    exit 1
fi

# Check Docker Compose
if docker compose version &> /dev/null; then
    COMPOSE_VERSION=$(docker compose version)
    print_success "$COMPOSE_VERSION"
else
    print_error "Docker Compose æœªå®‰è£"
    exit 1
fi

# Check NVIDIA Driver
if command -v nvidia-smi &> /dev/null; then
    print_success "NVIDIA Driver å·²å®‰è£"
    GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
    print_info "æª¢æ¸¬åˆ° $GPU_COUNT å¼µ GPU"

    if [ "$GPU_COUNT" -lt 2 ]; then
        print_warning "é æœŸæœ‰ 2 å¼µ GPUï¼Œä½†åªæª¢æ¸¬åˆ° $GPU_COUNT å¼µ"
        read -p "æ˜¯å¦ç¹¼çºŒéƒ¨ç½²ï¼Ÿ(y/N) " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
else
    print_error "NVIDIA Driver æœªå®‰è£"
    exit 1
fi

# Check NVIDIA Container Toolkit
if docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi &> /dev/null; then
    print_success "NVIDIA Container Toolkit é‹ä½œæ­£å¸¸"
else
    print_error "NVIDIA Container Toolkit ç„¡æ³•é‹ä½œ"
    print_info "è«‹åŸ·è¡Œ: sudo nvidia-ctk runtime configure --runtime=docker"
    exit 1
fi

# Check environment file
print_header "æª¢æŸ¥ç’°å¢ƒé…ç½®"

if [ ! -f .env.prod ]; then
    print_warning ".env.prod ä¸å­˜åœ¨"

    if [ -f .env.prod.template ]; then
        print_info "å¾ç¯„æœ¬å‰µå»º .env.prod..."
        cp .env.prod.template .env.prod
        chmod 600 .env.prod

        print_warning "è«‹ç·¨è¼¯ .env.prod ä¸¦å¡«å…¥å¯¦éš›çš„é…ç½®å€¼"
        print_info "å¿…é ˆé…ç½®çš„é …ç›®ï¼š"
        echo "  - POSTGRES_PASSWORD"
        echo "  - REDIS_PASSWORD"
        echo "  - RABBITMQ_DEFAULT_PASS"
        echo "  - OPENAI_API_KEY, ANTHROPIC_API_KEY, GEMINI_API_KEY"
        echo "  - LITELLM_MASTER_KEY"
        echo "  - GRAFANA_ADMIN_PASSWORD"
        echo ""

        read -p "æ˜¯å¦ç¾åœ¨ç·¨è¼¯ .env.prodï¼Ÿ(Y/n) " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Nn]$ ]]; then
            ${EDITOR:-vim} .env.prod
        else
            print_warning "è«‹æ‰‹å‹•ç·¨è¼¯ .env.prod å¾Œå†æ¬¡åŸ·è¡Œæ­¤è…³æœ¬"
            exit 1
        fi
    else
        print_error ".env.prod.template ä¹Ÿä¸å­˜åœ¨"
        exit 1
    fi
fi

print_success ".env.prod å·²å­˜åœ¨"

# Verify critical environment variables
print_info "é©—è­‰é—œéµç’°å¢ƒè®Šæ•¸..."
source .env.prod

REQUIRED_VARS=(
    "POSTGRES_PASSWORD"
    "REDIS_PASSWORD"
    "RABBITMQ_DEFAULT_PASS"
)

MISSING_VARS=()
for var in "${REQUIRED_VARS[@]}"; do
    if [ -z "${!var}" ] || [ "${!var}" = "<STRONG_PASSWORD_HERE>" ] || [ "${!var}" = "<STRONG_REDIS_PASSWORD_HERE>" ] || [ "${!var}" = "<STRONG_MQ_PASSWORD_HERE>" ]; then
        MISSING_VARS+=("$var")
    fi
done

if [ ${#MISSING_VARS[@]} -gt 0 ]; then
    print_error "ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸å°šæœªé…ç½®ï¼š"
    for var in "${MISSING_VARS[@]}"; do
        echo "  - $var"
    done
    exit 1
fi

print_success "ç’°å¢ƒè®Šæ•¸é©—è­‰é€šé"

# Ask for deployment mode
print_header "é¸æ“‡éƒ¨ç½²æ¨¡å¼"

echo "1) å®Œæ•´éƒ¨ç½² (å»ºæ§‹æ˜ åƒæª” + å•Ÿå‹•æœå‹™)"
echo "2) åƒ…å»ºæ§‹æ˜ åƒæª”"
echo "3) åƒ…å•Ÿå‹•æœå‹™ (å‡è¨­æ˜ åƒæª”å·²å»ºæ§‹)"
echo "4) æ›´æ–°ä¸¦é‡å•Ÿæœå‹™"
read -p "è«‹é¸æ“‡ [1-4]: " -n 1 -r DEPLOY_MODE
echo ""

case $DEPLOY_MODE in
    1)
        print_header "é–‹å§‹å®Œæ•´éƒ¨ç½²"
        SHOULD_BUILD=true
        SHOULD_START=true
        ;;
    2)
        print_header "é–‹å§‹å»ºæ§‹æ˜ åƒæª”"
        SHOULD_BUILD=true
        SHOULD_START=false
        ;;
    3)
        print_header "é–‹å§‹å•Ÿå‹•æœå‹™"
        SHOULD_BUILD=false
        SHOULD_START=true
        ;;
    4)
        print_header "é–‹å§‹æ›´æ–°ä¸¦é‡å•Ÿ"
        SHOULD_BUILD=true
        SHOULD_START=true
        print_info "å°‡åŸ·è¡Œ docker compose down å¾Œé‡æ–°å»ºæ§‹å’Œå•Ÿå‹•"
        docker compose --env-file .env.prod -f docker-compose.prod.yml down
        ;;
    *)
        print_error "ç„¡æ•ˆçš„é¸æ“‡"
        exit 1
        ;;
esac

# Build images
if [ "$SHOULD_BUILD" = true ]; then
    print_header "å»ºæ§‹ Docker æ˜ åƒæª”"

    print_info "æ­¤éç¨‹å¯èƒ½éœ€è¦ 20-40 åˆ†é˜ (é¦–æ¬¡å»ºæ§‹)"
    print_info "å»ºæ§‹ MCP Server (å« GPU æ”¯æ´)..."

    docker compose --env-file .env.prod -f docker-compose.prod.yml build --no-cache

    if [ $? -eq 0 ]; then
        print_success "æ˜ åƒæª”å»ºæ§‹å®Œæˆ"
    else
        print_error "æ˜ åƒæª”å»ºæ§‹å¤±æ•—"
        exit 1
    fi
fi

# Start services
if [ "$SHOULD_START" = true ]; then
    print_header "å•Ÿå‹•æœå‹™"

    # Start in phases
    print_info "éšæ®µ 1: å•Ÿå‹•è³‡æ–™åº«æœå‹™..."
    docker compose --env-file .env.prod -f docker-compose.prod.yml up -d postgres redis qdrant rabbitmq

    print_info "ç­‰å¾…è³‡æ–™åº«å°±ç·’ (30ç§’)..."
    sleep 30

    print_info "éšæ®µ 2: å•Ÿå‹• LiteLLM å’Œ Ollama..."
    docker compose --env-file .env.prod -f docker-compose.prod.yml up -d litellm ollama

    print_info "ç­‰å¾… LLM æœå‹™å°±ç·’ (20ç§’)..."
    sleep 20

    print_info "éšæ®µ 3: å•Ÿå‹• MCP Server (å« GPU)..."
    docker compose --env-file .env.prod -f docker-compose.prod.yml up -d mcp-server

    print_info "ç­‰å¾… MCP Server åˆå§‹åŒ– (å¯èƒ½éœ€è¦è¼‰å…¥ GPU æ¨¡å‹ï¼Œæœ€å¤š 2 åˆ†é˜)..."
    sleep 60

    print_info "éšæ®µ 4: å•Ÿå‹• Agent Service å’Œ Web UI..."
    docker compose --env-file .env.prod -f docker-compose.prod.yml up -d agent-service web-ui

    print_info "éšæ®µ 5: å•Ÿå‹•ç›£æ§æœå‹™..."
    docker compose --env-file .env.prod -f docker-compose.prod.yml up -d prometheus grafana

    print_success "æ‰€æœ‰æœå‹™å·²å•Ÿå‹•"

    print_info "ç­‰å¾…æœå‹™å®Œå…¨å°±ç·’ (30ç§’)..."
    sleep 30
fi

# Health check
print_header "å¥åº·æª¢æŸ¥"

check_service() {
    local url=$1
    local name=$2

    if curl -sf "$url" > /dev/null 2>&1; then
        print_success "$name: Healthy"
        return 0
    else
        print_error "$name: Unhealthy"
        return 1
    fi
}

HEALTH_STATUS=0

check_service "http://localhost:8501/_stcore/health" "Web UI" || HEALTH_STATUS=1
check_service "http://localhost:8002/health" "Agent Service" || HEALTH_STATUS=1
check_service "http://localhost:8001/health" "MCP Server" || HEALTH_STATUS=1
check_service "http://localhost:4000/health/readiness" "LiteLLM" || HEALTH_STATUS=1
check_service "http://localhost:9090/-/healthy" "Prometheus" || HEALTH_STATUS=1
check_service "http://localhost:3000/api/health" "Grafana" || HEALTH_STATUS=1

# Check GPU usage
print_header "GPU ç‹€æ…‹"

if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv,noheader

    print_info "æª¢æŸ¥å®¹å™¨ GPU é…ç½®..."

    # Check Ollama GPU
    OLLAMA_GPU=$(docker inspect ai-ollama-prod 2>/dev/null | jq -r '.[0].HostConfig.DeviceRequests[0].DeviceIDs[0]' 2>/dev/null || echo "N/A")
    if [ "$OLLAMA_GPU" != "N/A" ]; then
        print_success "Ollama ä½¿ç”¨ GPU: $OLLAMA_GPU"
    else
        print_warning "Ollama GPU é…ç½®æœªæª¢æ¸¬åˆ°"
    fi

    # Check MCP Server GPU
    MCP_GPU=$(docker inspect ai-mcp-server-prod 2>/dev/null | jq -r '.[0].HostConfig.DeviceRequests[0].DeviceIDs[0]' 2>/dev/null || echo "N/A")
    if [ "$MCP_GPU" != "N/A" ]; then
        print_success "MCP Server ä½¿ç”¨ GPU: $MCP_GPU"
    else
        print_warning "MCP Server GPU é…ç½®æœªæª¢æ¸¬åˆ°"
    fi
fi

# Test OCR
print_header "OCR åŠŸèƒ½æ¸¬è©¦"

OCR_STATUS=$(curl -s http://localhost:8001/tools/ocr_get_status 2>/dev/null)
if [ $? -eq 0 ]; then
    echo "$OCR_STATUS" | jq .

    DEEPSEEK_AVAILABLE=$(echo "$OCR_STATUS" | jq -r '.backends[] | select(.name=="DeepSeek-OCR") | .available' 2>/dev/null)
    if [ "$DEEPSEEK_AVAILABLE" = "true" ]; then
        print_success "DeepSeek-OCR (GPU) å·²å•Ÿç”¨"
    else
        print_warning "DeepSeek-OCR (GPU) æœªå•Ÿç”¨ï¼Œä½¿ç”¨ EasyOCR (CPU) ä½œç‚ºå¾Œå‚™"
    fi
else
    print_error "ç„¡æ³•æ¸¬è©¦ OCR åŠŸèƒ½"
fi

# Display service URLs
print_header "éƒ¨ç½²å®Œæˆ"

if [ $HEALTH_STATUS -eq 0 ]; then
    print_success "æ‰€æœ‰æœå‹™å¥åº·é‹è¡Œ"
else
    print_warning "éƒ¨åˆ†æœå‹™æœªèƒ½é€šéå¥åº·æª¢æŸ¥ï¼Œè«‹æŸ¥çœ‹æ—¥èªŒ"
fi

echo ""
echo "æœå‹™è¨ªå•åœ°å€ï¼š"
echo "  Web UI:        http://$(hostname -I | awk '{print $1}'):8501"
echo "  Agent Service: http://$(hostname -I | awk '{print $1}'):8002"
echo "  MCP Server:    http://$(hostname -I | awk '{print $1}'):8001"
echo "  LiteLLM:       http://$(hostname -I | awk '{print $1}'):4000"
echo "  Grafana:       http://$(hostname -I | awk '{print $1}'):3000"
echo "  Prometheus:    http://$(hostname -I | awk '{print $1}'):9090"
echo ""

print_info "æŸ¥çœ‹æœå‹™æ—¥èªŒï¼š"
echo "  docker compose --env-file .env.prod -f docker-compose.prod.yml logs -f <service_name>"
echo ""

print_info "æŸ¥çœ‹æ‰€æœ‰æœå‹™ç‹€æ…‹ï¼š"
echo "  docker compose --env-file .env.prod -f docker-compose.prod.yml ps"
echo ""

print_info "ç›£æ§ GPU ä½¿ç”¨ï¼š"
echo "  watch -n 1 nvidia-smi"
echo ""

print_success "éƒ¨ç½²å®Œæˆï¼ğŸ‰"
