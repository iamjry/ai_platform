# GPU-Optimized Docker Compose for Production (RHEL 9.4 with NVIDIA H100L)
# Usage: docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d

version: '3.8'

services:
  # Ollama with GPU acceleration
  ollama:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1  # Use 1 of 2 available GPUs
              capabilities: [gpu]
        limits:
          memory: 32G
    environment:
      - NVIDIA_VISIBLE_DEVICES=0  # Use GPU 0
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_GPU_OVERHEAD=2048  # 2GB overhead for H100L
      - OLLAMA_MAX_LOADED_MODELS=4
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_FLASH_ATTENTION=1
    volumes:
      - model_cache:/root/.ollama
      - /tmp/.X11-unix:/tmp/.X11-unix:rw

  # LiteLLM proxy with enhanced configuration
  litellm:
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
    environment:
      - GPU_AVAILABLE=true
      - LITELLM_DROP_PARAMS=true
      - LITELLM_NUM_WORKERS=8
      - LITELLM_REQUEST_TIMEOUT=600
    command: --config /app/config.yaml --port 4000 --num_workers 8 --timeout 600

  # MCP Server with increased resources
  mcp-server:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      restart_policy:
        condition: on-failure
        max_attempts: 3

  # Agent Service with increased resources
  agent-service:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    environment:
      - MAX_CONCURRENT_TASKS=50
      - TASK_TIMEOUT=600
      - GPU_ENABLED=true

  # PostgreSQL with production tuning
  postgres:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
    command: >
      postgres
      -c shared_buffers=2GB
      -c effective_cache_size=6GB
      -c maintenance_work_mem=512MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=10MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=8
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8

  # Redis with production configuration
  redis:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 3gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec

  # RabbitMQ with production settings
  rabbitmq:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 0.8

  # Prometheus with larger retention
  prometheus:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.enable-lifecycle'

  # Grafana with production settings
  grafana:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3000}
      GF_SMTP_ENABLED: ${SMTP_ENABLED:-false}
      GF_SMTP_HOST: ${SMTP_SERVER:-}:${SMTP_PORT:-587}
      GF_SMTP_USER: ${SMTP_USERNAME:-}
      GF_SMTP_PASSWORD: ${SMTP_PASSWORD:-}
