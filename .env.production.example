# ==================== AI Platform Production Environment Configuration ====================
# Red Hat Enterprise Linux 9.4 with 2x NVIDIA H100 GPUs
#
# SECURITY WARNING:
# - Never commit this file with actual secrets to version control
# - Use strong, unique passwords for production
# - Rotate credentials regularly
# - Store secrets in a secure vault (HashiCorp Vault, AWS Secrets Manager, etc.)

# ==================== Environment Settings ====================
ENVIRONMENT=production
LOG_LEVEL=info
DEBUG=false
MAX_CONCURRENT_REQUESTS=200

# ==================== API Keys ====================
# OpenAI API (GPT-4, GPT-3.5, etc.)
OPENAI_API_KEY=sk-proj-your-production-openai-key-here

# Anthropic API (Claude 3 models)
ANTHROPIC_API_KEY=sk-ant-your-production-anthropic-key-here

# Google Gemini API
GEMINI_API_KEY=your-production-gemini-api-key-here

# Web Search APIs (Optional but recommended)
TAVILY_API_KEY=tvly-your-production-tavily-key-here
SERPAPI_API_KEY=your-production-serpapi-key-here

# ==================== Database Configuration ====================
# PostgreSQL Primary Database
# IMPORTANT: Generate secure passwords using: openssl rand -base64 32 | tr -d "=+/" | cut -c1-25
POSTGRES_USER=ai_admin
POSTGRES_PASSWORD=CHANGE_ME_TO_SECURE_PASSWORD_1
POSTGRES_DB=ai_platform

# Database Pool Settings
POSTGRES_MAX_CONNECTIONS=200
POSTGRES_SHARED_BUFFERS=2GB

# ==================== Redis Configuration ====================
REDIS_PASSWORD=CHANGE_ME_TO_SECURE_PASSWORD_2
REDIS_MAX_MEMORY=4gb
REDIS_MAX_MEMORY_POLICY=allkeys-lru

# ==================== RabbitMQ Configuration ====================
RABBITMQ_DEFAULT_USER=ai_rabbitmq
RABBITMQ_DEFAULT_PASS=CHANGE_ME_TO_SECURE_PASSWORD_3

# ==================== GPU Configuration ====================
# Enable GPU acceleration (REQUIRED for H100 deployment)
ENABLE_GPU=true
GPU_MEMORY_UTILIZATION=0.9

# GPU Device Selection (0,1 for 2x H100)
CUDA_VISIBLE_DEVICES=0,1

# Ollama GPU Settings
OLLAMA_NUM_PARALLEL=4
OLLAMA_MAX_LOADED_MODELS=2
OLLAMA_FLASH_ATTENTION=1

# ==================== LiteLLM Configuration ====================
LITELLM_MASTER_KEY=CHANGE_ME_TO_SECURE_PASSWORD_4
LITELLM_CACHE=True
LITELLM_CACHE_TYPE=redis
LITELLM_MAX_PARALLEL_REQUESTS=200

# ==================== SMTP Email Configuration ====================
# For production email notifications
SMTP_SERVER=smtp.your-production-mail-server.com
SMTP_PORT=587
SMTP_USERNAME=notifications@your-domain.com
SMTP_PASSWORD=CHANGE_ME_TO_SECURE_PASSWORD_5
SMTP_FROM_EMAIL=ai-platform@your-domain.com
SMTP_USE_TLS=true

# ==================== LINE Messaging API (Optional) ====================
LINE_CHANNEL_ACCESS_TOKEN=your-production-line-channel-access-token
LINE_DEFAULT_RECIPIENT_ID=your-production-line-recipient-id
LINE_USER_ID=your-production-line-user-id

# ==================== Monitoring Configuration ====================
# Grafana Admin Credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=CHANGE_ME_TO_SECURE_PASSWORD_6
GRAFANA_ROOT_URL=https://your-domain.com/grafana

# Prometheus Settings
PROMETHEUS_RETENTION_TIME=90d

# Alert Manager (Optional)
ALERTMANAGER_URL=http://alertmanager:9093

# ==================== SSL/TLS Configuration ====================
# SSL Certificate Paths (for NGINX reverse proxy)
SSL_CERTIFICATE_PATH=/etc/nginx/ssl/fullchain.pem
SSL_CERTIFICATE_KEY_PATH=/etc/nginx/ssl/privkey.pem

# ==================== Backup Configuration ====================
# Automated Backup Settings
BACKUP_ENABLED=true
BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM
BACKUP_RETENTION_DAYS=30
BACKUP_S3_BUCKET=your-s3-backup-bucket
BACKUP_S3_REGION=us-east-1

# AWS Credentials for S3 Backups (if using S3)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key

# ==================== Security Configuration ====================
# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# CORS Settings
CORS_ALLOWED_ORIGINS=https://your-domain.com,https://app.your-domain.com

# Session Settings
SESSION_SECRET=CHANGE_ME_TO_SECURE_PASSWORD_7
SESSION_TIMEOUT=3600

# ==================== Performance Tuning ====================
# Worker Processes
AGENT_SERVICE_WORKERS=8
MCP_SERVER_WORKERS=8
LITELLM_WORKERS=8

# Connection Pool Sizes
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40

# Request Timeouts (seconds)
REQUEST_TIMEOUT=300
WEBSOCKET_TIMEOUT=600

# ==================== Feature Flags ====================
ENABLE_WEB_SEARCH=true
ENABLE_VECTOR_SEARCH=true
ENABLE_EMAIL_NOTIFICATIONS=true
ENABLE_LINE_NOTIFICATIONS=false
ENABLE_API_DOCUMENTATION=true

# ==================== Compliance & Audit ====================
ENABLE_AUDIT_LOGGING=true
AUDIT_LOG_RETENTION_DAYS=90
ENABLE_DATA_ENCRYPTION=true

# ==================== Custom Application Settings ====================
APP_NAME="AI Platform Production"
APP_VERSION=2.0.0
APP_DOMAIN=your-domain.com
APP_SUPPORT_EMAIL=support@your-domain.com

# Timezone
TZ=Asia/Taipei

# ==================== Model Configuration ====================
# Default Model Settings
DEFAULT_MODEL=claude-3-5-sonnet
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000

# Model Cost Tracking
ENABLE_COST_TRACKING=true
COST_ALERT_THRESHOLD_USD=1000

# ==================== Network Configuration ====================
# Service Ports (Internal - Docker network)
MCP_SERVER_PORT=8000
AGENT_SERVICE_PORT=8000
WEB_UI_PORT=8501
LITELLM_PORT=4000

# External Ports (Host machine)
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# ==================== Logging Configuration ====================
LOG_FORMAT=json
LOG_FILE_MAX_SIZE=100MB
LOG_FILE_MAX_BACKUPS=5
LOG_FILE_MAX_AGE=30

# Syslog (Optional)
ENABLE_SYSLOG=false
SYSLOG_HOST=localhost
SYSLOG_PORT=514

# ==================== Health Check Configuration ====================
HEALTH_CHECK_INTERVAL=10s
HEALTH_CHECK_TIMEOUT=5s
HEALTH_CHECK_RETRIES=5

# ==================== Production Deployment Info ====================
DEPLOYMENT_DATE=2025-10-29
DEPLOYED_BY=DevOps Team
GIT_COMMIT=
BUILD_NUMBER=

# ==================== Notes ====================
# 1. Replace all "CHANGE_ME_TO_SECURE_PASSWORD_*" with strong, unique passwords
# 2. Verify all API keys are production keys (not test keys)
# 3. Update SSL certificate paths with actual certificate locations
# 4. Configure firewall rules to allow only necessary ports
# 5. Set up regular backup verification
# 6. Configure monitoring alerts in Grafana
# 7. Test disaster recovery procedures before going live
# 8. Review and update CORS settings for your domain
# 9. Ensure NVIDIA drivers and CUDA are properly installed
# 10. Verify GPU access: docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubi9 nvidia-smi
